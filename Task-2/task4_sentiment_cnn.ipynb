{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2.4: Text classification via CNN (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you should perform sentiment analysis of the IMDB reviews based on CNN architecture. Read carefully [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/pdf/1408.5882.pdf) by Yoon Kim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext import datasets\n",
    "from torchtext.data import Field, LabelField\n",
    "from torchtext.data import Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(sequential=True, lower=True, batch_first=True)\n",
    "LABEL = LabelField(batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, tst = datasets.IMDB.splits(TEXT, LABEL)\n",
    "trn, vld = train.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "TEXT.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Iterator (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an iterator here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import BucketIterator\n",
    "\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "        (trn, vld, tst),\n",
    "        batch_sizes=(64, 64, 64),\n",
    "        sort=True,\n",
    "        sort_key=lambda x: len(x.text),\n",
    "        sort_within_batch=False,\n",
    "        device='cuda',\n",
    "        repeat=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN-based text classification model (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, V, D, kernel_sizes, dropout=0.5):\n",
    "        super(CNN, self).__init__()\n",
    "        self.emb = nn.Embedding(V, D)\n",
    "        self.convs = nn.Sequential(\n",
    "            *[nn.Sequential(\n",
    "                nn.Conv1d(D // (i + 1), D // (i + 2), kernel_size),\n",
    "                nn.ReLU(),\n",
    "            ) for i, kernel_size in enumerate(kernel_sizes)],\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "            \n",
    "        )\n",
    "        self.fc = nn.Linear(D // (len(kernel_sizes) + 1), 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.emb(x)\n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "        conv_out = self.convs(embedded).permute(0, 2, 1).view(x.shape[0], -1)\n",
    "        logits = self.fc(conv_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sizes = [3,4,5]\n",
    "vocab_size = len(TEXT.vocab)\n",
    "dropout = 0.5\n",
    "dim = 300\n",
    "\n",
    "model = CNN(vocab_size, dim, kernel_sizes, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (emb): Embedding(201569, 300)\n",
       "  (convs): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv1d(300, 150, kernel_size=(3,), stride=(1,))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv1d(150, 100, kernel_size=(4,), stride=(1,))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(100, 75, kernel_size=(5,), stride=(1,))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (3): AdaptiveAvgPool1d(output_size=1)\n",
       "  )\n",
       "  (fc): Linear(in_features=75, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training loop (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the optimization function and the loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=3e-4)\n",
    "loss_func = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think carefully about the stopping criteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.009209398308822087, Validation Loss: 0.008331149073441823\n",
      "Epoch: 2, Training Loss: 0.006368021609101977, Validation Loss: 0.006764837757746379\n",
      "Epoch: 3, Training Loss: 0.00552402412210192, Validation Loss: 0.014815388214588165\n",
      "Epoch: 4, Training Loss: 0.003656219011545181, Validation Loss: 0.006566977659861247\n",
      "CPU times: user 30.3 s, sys: 78.7 ms, total: 30.4 s\n",
      "Wall time: 30.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train() \n",
    "    for batch in train_iter:         \n",
    "        \n",
    "        x = batch.text\n",
    "        y = batch.label.view(-1, 1).type(torch.float)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        preds = model(x)\n",
    "        loss = loss_func(preds, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    epoch_loss = running_loss / len(trn)\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0 \n",
    "    for batch in val_iter:\n",
    "        \n",
    "        x = batch.text\n",
    "        y = batch.label.view(-1, 1).type(torch.float)\n",
    "        \n",
    "        preds = model(x)\n",
    "        loss = loss_func(preds, y)\n",
    "        val_loss += loss.item()\n",
    "        \n",
    "    val_loss /= len(vld)\n",
    "    \n",
    "    print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, epoch_loss, val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate performance of the trained model (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.826\n",
      "precision: 0.788\n",
      "recall: 0.894\n",
      "f1: 0.837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_true = np.zeros(len(tst))\n",
    "y_pred = np.zeros(len(tst))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_iter):\n",
    "        x = batch.text\n",
    "        y = batch.label\n",
    "        y_batch_pred = torch.exp(model(x))\n",
    "        y_true[i * 64 : (i + 1) * 64] = y.cpu().numpy()\n",
    "        y_pred[i * 64 : (i + 1) * 64] = y_batch_pred.cpu().numpy().flatten() > 0.5\n",
    "\n",
    "print(f'accuracy: {round(accuracy_score(y_true, y_pred), 3)}')\n",
    "print(f'precision: {round(precision_score(y_true, y_pred), 3)}')\n",
    "print(f'recall: {round(recall_score(y_true, y_pred), 3)}')\n",
    "print(f'f1: {round(f1_score(y_true, y_pred), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down the calculated performance\n",
    "\n",
    "### Accuracy: 0.826\n",
    "### Precision: 0.788\n",
    "### Recall: 0.894\n",
    "### F1: 0.837"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments (5 points)\n",
    "\n",
    "Experiment with the model and achieve better results. Implement and describe your experiments in details, mention what was helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ?\n",
    "### 2. ?\n",
    "### 3. ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
